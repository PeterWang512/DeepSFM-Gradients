•	Inspired by “Unsupervised Learning of Depth and Ego-Motion from Video” by Zhou et al., which utilized novel view synthesis in structure from motion to generate objective that is well-suited for unsupervised learning of depth with only a single frame as input <br />
•	Based on the result from the paper, incorporated Mask R-CNN results to incorporate object boundary cues as an additional regulation during the learning process that helps render sharper object boundaries in predicted depth maps after training

Project report can be found [here](https://drive.google.com/file/d/1gMRevc841n-wSQg3SJbllFecCR2D0rvK/view?usp=sharing) 
